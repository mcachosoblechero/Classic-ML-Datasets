{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Kaggle Submission\n",
    "\n",
    "This notebook encapsulates all the lessons from the previous two notebooks, creating a final submission for Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# Modelling\n",
    "# Standard Machine Learning Algorithms\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "# Silect XGBoost\n",
    "xgboost.config_context(verbosity=0)\n",
    "\n",
    "# Neural Networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils import preprocessing_tools\n",
    "\n",
    "print(\"Tensorflow version \" + str(tf.__version__))\n",
    "\n",
    "config = {\n",
    "    'seed': 14,\n",
    "    'balance_dataset': True,\n",
    "\n",
    "    # NN Parameters\n",
    "    'batch_size': 50,\n",
    "    \"no_epochs\": 25\n",
    "}\n",
    "\n",
    "train_data = pd.read_csv('../input/train.csv')\n",
    "train_data.head(5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
